\section{Introduction}
Many problems cannot be solved on "sequential" systems. In order to have a meaningful performance computers exploit parallelism (since 1955).
\subsection{Overview}
%\subsubsection{Parallel vs. Concurrent}
\begin{description}
\item[Parallel] For two concurrent activities $A$ and $B$, $A$ and $B$ are executed in \emph{parallel} when $A$ may be executed while $B$ is executed. 
	\begin{itemize}
		\item $A$ starts at time $T1$, ends at $T3$
		\item $B$ starts at time $T2$, ends at $T4$
		\item Intervals $(T1, T2)$ and $(T2, T4)$ may overlap. 
		\item Execution can be by separate unit (resource) or by interleaved use of one resource.
		
	\end{itemize}

\item[Concurrent] For two concurrent activities $A$ and $B$, $A$ and $B$ are executed \emph{concurrently} when $A$ is executed while $B$ is executed.
	\begin{itemize}
		\item This usually requires separate resources. 
	\end{itemize}
 
\end{description}

\paragraph{Activity} is a part of a machine operation on compound, scalar data or a sequence of operations. And can be supported by a \emph{Hardware platform} as:
\begin{itemize}
\item As part of a machine operation on scalar data:
	\begin{description}
		\item Instruction-level parallelism (ILP). \emph{Handled by the Compiler}
			\begin{itemize}
				\item Pipelining
				\item (Very) Long instruction words (VLIW)
				\item Superscalar
			\end{itemize}
	\end{description}
\item Machine operation on compound data. \emph{Handled by the compiler or offloaded to a library}
	\begin{description}
		\item Vector instructions
	\end{description}
\item Sequence of operations. \emph{Handled by expert programmers or sometimes the compiler}
	\begin{description}
		\item Multiprocessors
		\item Multicores
		\item Hyper-threading
	\end{description}
\end{itemize}

\paragraph{Sequence of operations} are for many reasons the most interesting part of spectrum since we have:
\begin{itemize}
	\item Platform issues
	\item Software issues
\end{itemize}

\paragraph{Threads} are an "execution of an instruction sequence":
\begin{itemize}
	\item Instruction sequence
	\item Pointer to next instruction
\end{itemize}

\paragraph{Thread Communication} can be done either through
\begin{itemize}
	\item \emph{Explicit communication}: {\bf Message passing}
		\begin{description}
			\item Example Systems:
			\begin{itemize}
				\item MPI	
				\item PVM
				\item many OS (Thoth, Demos, ...)
			\end{itemize}
		\end{description}

	\item \emph{Implicit communication}: {\bf Shared memory}
		\begin{description}
			\item Reality of System Design: Caching
		\end{description}
\end{itemize}


\paragraph{Coordination} of threads can be achieved through
\begin{itemize}
	\item \emph{Synchronization} by using
		\begin{description}
			\item Mutual exclusion (for data access)
			\item Critical sections
			\item Waiting
		\end{description}
		with
		\begin{itemize}
			\item Special hardware instructions such as \emph{test-and-set} or \emph{increment-and-set}
			\item Runtime system services
			\item Programming language support
		\end{itemize}

	\item \emph{Barriers} with
		\begin{itemize}
			\item Dedicated network(s)
			\item Combining network
			\item Software implementations
		\end{itemize}
\end{itemize}

\subsection{History of Performance Gains}
\subsubsection{Clock Rate}
\begin{itemize}
	\item Get more cycles $\implies$ do the same work faster
	\item Heat dissipation (too much, too hard to dissipate)
	\item Power consumption too high (example: mobile devices)
	\item Electric current leakage problem
\end{itemize}

\subsubsection{Execution Optimisation}
Do more work per cycle
\begin{itemize}
	\item Increase instruction level parallelism (ILP)
	\item Instruction prefetching and reordering
	\item Pipelined function units, branch prediction
	\item Out-of-order execution
\end{itemize}
\subsubsection{Cache}
Stay away from RAM
\begin{itemize}
	\item Increasing cache size (from few KB to several MB)
	\item More cache levels (up to 3 levels)
	\item Working set should fit in cache (but applications manipulate more data)
\end{itemize}

\subsection{New Performance Drivers}
Instead of increasing clock clock speeds and instruction throughput we get:
\begin{description}
	\item[Simultaneous multithreading] Running 2+ hardware threads in parallel inside a processor
		\begin{itemize}
			\item SMT-processor appears to OS as 2 (logical) processors (OS can schedule 2 threads simultaneously)
			\item \emph{Limitation}: Only 1 processor (cache, FPU, etc...)
		\end{itemize}
	\item[Multicore] 2+ cores in a single processor
\end{description}

\subsection{Moore's law}
The number of transistors doubles every 2 years:
\begin{itemize}
	\item This predicts exponential growth for transistor densities
	\item Also applies to other related areas (such as clock speed)
\end{itemize}
unfortunately this is restricted with physical limits (see paper "The free Lunch is over")


